# Spark: apresentando a ferramenta
## Começando o trabalho
* Conhecemos o projeto Apache Spark.
* Falamos sobre a interface para Apache Spark em Python.
* Conhecemos os recursos do Spark.
* Aprendemos a configurar o Spark no sistema operacional Windows.
* Vimos como utilizar o Spark em nosso notebook do Colab.
## Carregamento de dados
* Como iniciar uma SparkSession.
* Conhecemos os métodos e atributos básicos da classe SparkSession.
* Como criar Spark DataFrames.
* Como carregar conteúdo de arquivos CSV particionados em uma DataFrame do Spark.
## Manipulando os dados
* Como alterar os nomes das colunas de um DataFrame.
* Como identificar os tipos de variáveis em um DataFrames.
* Os tipos de dados suportados pelo Spark.
* Algumas funções básicas do Spark e como aplicá-las.
* Como fazer algumas conversões de tipo.
## Seleções e consultas
* Selecionar colunas específicas de um DataFrame.
* Criar colunas em um DataFrame.
* Ordenar os dados de um DataFrame.
* Fazer filtros com as colunas de um DataFrame.
* Fazer busca por conteúdos específicos em uma coluna de um DataFrame.
## Agregações e junções
* Gerar agrupamentos com o método groupBy;
* Criar sumarizações com os métodos agg e summary;
* Utilizar o método join para fazer junções entre DataFrame com o uso de chaves de ligação;
* Usar o método sql para escrever queries com expressões SQL tradicionais.
## Formas de armazenamento
* Como criar arquivos CSV com o conteúdo de DataFrames do Spark;
* Sobre o projeto Apache Parquet;
* Como criar arquivos PARQUET com o conteúdo de DataFrames do Spark;
* Como configurar o particionamento de arquivos no Spark.
